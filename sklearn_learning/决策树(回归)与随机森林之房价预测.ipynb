{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树(回归)的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,), numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# 导入房价预测数据集\n",
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "\n",
    "# 实例化数据集类并命名\n",
    "housing = fetch_california_housing()\n",
    "# 查看训练集，目标集数据维度\n",
    "housing.data.shape , housing.target.shape, type(housing.data), type(housing.target)\n",
    "# df = pd.DataFrame(housing.data, columns = housin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "# 实例化决策树回归模型实例并命名\n",
    "dtr = tree.DecisionTreeRegressor(max_depth=2)\n",
    "# 把数据及喂给模型\n",
    "dtr.fit(housing.data[:,[6,7]], housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'housing1.pdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化展示，需要首先安装graphviz\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dtr, \n",
    "                               feature_names =housing.feature_names[6:9],\n",
    "                               filled=True,\n",
    "                               impurity=False,\n",
    "                               rounded=True)\n",
    "graph1 = graphviz.Source(dot_data)\n",
    "graph1.render('housing1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先对数据进行数据拆分\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 用拆包的方法接收train_test_split函数的结果, test_size指的是取测试集占训练集的比例\n",
    "data_train,data_test,target_train,target_test = \\\n",
    "    train_test_split(housing.data, housing.target, test_size=0.1, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面创建3个模型\n",
    "##### 1.单树DT\n",
    "##### 2.随机森林RF\n",
    "##### 3.自动优化参数的随机森林RF-grid\n",
    "##### 分别用以上分割的数据集来进行准确率得分计算（保证用同一随机数种子来确保数据来自同一份split数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274613003586686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"单树模型（回归）\"\"\"\n",
    "\n",
    "# 实例化一个新的树模型来记录决策树（单树）的训练分数,这里保持随机数种子是23不变\n",
    "dtr_test = tree.DecisionTreeRegressor(random_state=23)\n",
    "# 喂入分割好的训练集\n",
    "dtr_test.fit(data_train,target_train)\n",
    "# 用测试集计算准确率\n",
    "dtr_test.score(data_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7742669601400837"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "随机森林模型（回归）\n",
    "\n",
    "随机：1.在训练集中有放回地、随机地选取一定比例的样本进行模型训练\n",
    "     2.在训练的过程中随机选取一定比例的特征（不可重复）\n",
    "森林：以以上的12步选取的树为元素，建立多棵树，最后的模型参数采取所有树中的平均值\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 实例化模型并命名（保持随机数种子random_state不变,树数量n_estimators默认为10棵）\n",
    "rfr = RandomForestRegressor(random_state=23)\n",
    "# 把训练数据喂给随机森林模型\n",
    "rfr.fit(data_train,target_train)\n",
    "# 用测试集计算准确率\n",
    "rfr.score(data_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.93880816, 4.6374886 , 9.39000931, 0.89419236, 4.45629401,\n",
       "         8.70843906, 0.89559312, 4.19346924, 8.17265029]),\n",
       "  'std_fit_time': array([0.01030952, 0.07521436, 0.19227996, 0.04398108, 0.05589763,\n",
       "         0.04018129, 0.12316048, 0.07159344, 0.08660677]),\n",
       "  'mean_score_time': array([0.01040692, 0.04643183, 0.09466386, 0.00840607, 0.04002652,\n",
       "         0.07965245, 0.00760608, 0.03602409, 0.06924553]),\n",
       "  'std_score_time': array([0.00149791, 0.0008019 , 0.00280169, 0.00049015, 0.00178934,\n",
       "         0.00492536, 0.0004906 , 0.00167525, 0.0014702 ]),\n",
       "  'param_min_samples_split': masked_array(data=[3, 3, 3, 6, 6, 6, 9, 9, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'min_samples_split': 3, 'n_estimators': 10},\n",
       "   {'min_samples_split': 3, 'n_estimators': 50},\n",
       "   {'min_samples_split': 3, 'n_estimators': 100},\n",
       "   {'min_samples_split': 6, 'n_estimators': 10},\n",
       "   {'min_samples_split': 6, 'n_estimators': 50},\n",
       "   {'min_samples_split': 6, 'n_estimators': 100},\n",
       "   {'min_samples_split': 9, 'n_estimators': 10},\n",
       "   {'min_samples_split': 9, 'n_estimators': 50},\n",
       "   {'min_samples_split': 9, 'n_estimators': 100}],\n",
       "  'split0_test_score': array([0.8047616 , 0.81910924, 0.82143837, 0.80478996, 0.81908561,\n",
       "         0.82072654, 0.80755238, 0.81867344, 0.82008448]),\n",
       "  'split1_test_score': array([0.78666095, 0.80852302, 0.8130678 , 0.79078552, 0.80922779,\n",
       "         0.81261765, 0.79173582, 0.80804373, 0.81119911]),\n",
       "  'split2_test_score': array([0.78113885, 0.80221274, 0.80379511, 0.78379631, 0.80212887,\n",
       "         0.80381128, 0.78476855, 0.80188621, 0.80361879]),\n",
       "  'split3_test_score': array([0.78068681, 0.80042358, 0.80477604, 0.78429522, 0.80097076,\n",
       "         0.80459215, 0.78340685, 0.80020634, 0.80361853]),\n",
       "  'split4_test_score': array([0.78201558, 0.79996358, 0.80220149, 0.78440815, 0.7998435 ,\n",
       "         0.80115774, 0.78468521, 0.79925732, 0.80034319]),\n",
       "  'mean_test_score': array([0.78705371, 0.80604713, 0.80905643, 0.78961585, 0.806252  ,\n",
       "         0.80858172, 0.79043068, 0.80561411, 0.80777348]),\n",
       "  'std_test_score': array([0.00910705, 0.00721273, 0.00724464, 0.00801202, 0.00720483,\n",
       "         0.00717775, 0.00904784, 0.00721153, 0.00711417]),\n",
       "  'rank_test_score': array([9, 5, 1, 8, 4, 2, 7, 6, 3])},\n",
       " {'min_samples_split': 3, 'n_estimators': 100},\n",
       " 0.8090564291191731)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "优化参数的随机森林（树的数量，节点分裂最小样本数）\n",
    "\n",
    "GridSearchCV是一个通过内置for循环来帮助选择模型参数的工具\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 把参数及其候选值通过dict的格式传递给一个变量tree_parm_grid\n",
    "tree_parm_grid = {'min_samples_split':list((3,6,9)), 'n_estimators':list((10,50,100))}\n",
    "# 实例化并命名grid模型\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=23),param_grid = tree_parm_grid,cv=5,return_train_score=False)\n",
    "# 把训练集喂给grid模型\n",
    "grid.fit(data_train,target_train,)\n",
    "# 打印分数列表、最优参数及其分数\n",
    "grid.cv_results_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-28750e04e744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 查看残差平方均值MSE(The mean squared error)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"残差平方均值MSE: %.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Explained variance score: 1 is perfect prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "# 把分数最好的参数扔给随机森林模型\n",
    "rfr_best = RandomForestRegressor(min_samples_split=3,n_estimators=100,random_state=23)\n",
    "rfr_best.fit(data_train,target_train)\n",
    "# rfr_best.score(data_test,target_test)\n",
    "target_test_pred = rfr_best.predict(data_test)\n",
    "\n",
    "# 查看残差平方均值MSE(The mean squared error)\n",
    "print(\"残差平方均值MSE: %.2f\" % mean_squared_error(target_test, target_test_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction \n",
    "#  R2 决定系数（拟合优度）\n",
    "# 模型越好：r2→1\n",
    "# 模型越差：r2→0\n",
    "print('拟合优度R2: %.2f' % r2_score(target_test,target_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 显示最佳模型rfr_best的参数parameters\n",
    "pd.Series(rfr_best.feature_importances_,index=housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"数据可视化\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "y_importances = rfr_best.feature_importances_\n",
    "x_importances = housing.feature_names\n",
    "y_pos = np.arange(len(x_importances))\n",
    "# 横向柱状图\n",
    "plt.barh(y_pos, y_importances, align='center')\n",
    "plt.yticks(y_pos, x_importances)\n",
    "plt.xlabel('Importances')\n",
    "plt.xlim(0,1)\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
